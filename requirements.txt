llama-cpp-python>=0.2.20
huggingface-hub>=0.19.0
transformers>=4.48.0
# Use CPU-only PyTorch to reduce download size (~200MB vs 2GB+ for CUDA version)
--extra-index-url https://download.pytorch.org/whl/cpu
torch>=2.0.0
accelerate
safetensors
playwright>=1.40.0
langchain>=0.1.0
langchain-community>=0.0.10
reportlab>=4.0.0
Pillow>=10.0.0
